{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4lA0kvR8c11lyq5oZFmEw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"bd73fe6608a6415fbc2dcd716170495c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c04ea682c6ba48089c45fb977e5b3dcd","IPY_MODEL_9bec03f0183349d2a24c0fa5e41f9357","IPY_MODEL_a4ead4777c2e42d9be36337aefa489b0"],"layout":"IPY_MODEL_8b0e8399b1ac489b8a98652d53070c01"}},"c04ea682c6ba48089c45fb977e5b3dcd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb0f5a203bb841309da02c77d848aad5","placeholder":"​","style":"IPY_MODEL_8d3c6335f8f640e1aa23641a25dde411","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"9bec03f0183349d2a24c0fa5e41f9357":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fafb479fa534712a7ea63b535f05076","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0f77f7a998b459ca982365083515a45","value":231508}},"a4ead4777c2e42d9be36337aefa489b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_911b97cf15374092be785cb9e6666853","placeholder":"​","style":"IPY_MODEL_58780d38cf9a4dfbafcc7add93be7ccf","value":" 232k/232k [00:00&lt;00:00, 2.59MB/s]"}},"8b0e8399b1ac489b8a98652d53070c01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb0f5a203bb841309da02c77d848aad5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d3c6335f8f640e1aa23641a25dde411":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fafb479fa534712a7ea63b535f05076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0f77f7a998b459ca982365083515a45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"911b97cf15374092be785cb9e6666853":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58780d38cf9a4dfbafcc7add93be7ccf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9550fb842c3449d397d573be736fae7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa30bf91827e4a849eddcbb737749861","IPY_MODEL_e4f9724ab36344d293f6efb37a462f15","IPY_MODEL_b603bbd46b2d4fe79169bda5533b4cf6"],"layout":"IPY_MODEL_4f4908fc003c40ec92c0ceecd2e9b690"}},"fa30bf91827e4a849eddcbb737749861":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59c27d9003684277bbeeaf92bba37e59","placeholder":"​","style":"IPY_MODEL_57336f7802d941fab459d122d2671851","value":"Downloading (…)okenizer_config.json: 100%"}},"e4f9724ab36344d293f6efb37a462f15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0f756f2744f48c9a48601cfe6a16ef5","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9238bab39854b539ec93d7221b38fd0","value":28}},"b603bbd46b2d4fe79169bda5533b4cf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59a64c983a144e499e27a2c467403143","placeholder":"​","style":"IPY_MODEL_49a562e48d044c1abe18f72e98f819d7","value":" 28.0/28.0 [00:00&lt;00:00, 1.12kB/s]"}},"4f4908fc003c40ec92c0ceecd2e9b690":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59c27d9003684277bbeeaf92bba37e59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57336f7802d941fab459d122d2671851":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0f756f2744f48c9a48601cfe6a16ef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9238bab39854b539ec93d7221b38fd0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59a64c983a144e499e27a2c467403143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49a562e48d044c1abe18f72e98f819d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"478134f5264040dc9b1a1590b823063c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efe7d778a22248b985d2c355b02e0d75","IPY_MODEL_b992b46c5c4d44ac9768d0a3c3d9eb37","IPY_MODEL_ab21bb95bde2449b8836d7ba04ee8c84"],"layout":"IPY_MODEL_79cc888a6c3b4892b2418dce30782b11"}},"efe7d778a22248b985d2c355b02e0d75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91d8ab2a0a9c4ea9b9712cc1a93538f4","placeholder":"​","style":"IPY_MODEL_34cb562d7a764d49add996a7c6da46fa","value":"Downloading (…)lve/main/config.json: 100%"}},"b992b46c5c4d44ac9768d0a3c3d9eb37":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05b334ad42cb446cb6e3baa5612a7184","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c48f982799342c1b2146476bd25548c","value":570}},"ab21bb95bde2449b8836d7ba04ee8c84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_daed9f1a6d5a4e9c852060d010dd7374","placeholder":"​","style":"IPY_MODEL_d294bf386321402cbde519827887f67f","value":" 570/570 [00:00&lt;00:00, 22.0kB/s]"}},"79cc888a6c3b4892b2418dce30782b11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91d8ab2a0a9c4ea9b9712cc1a93538f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34cb562d7a764d49add996a7c6da46fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05b334ad42cb446cb6e3baa5612a7184":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c48f982799342c1b2146476bd25548c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"daed9f1a6d5a4e9c852060d010dd7374":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d294bf386321402cbde519827887f67f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"960fc6bfacac4457b4b7214506807f84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92033821313240abb255bc1c2954089d","IPY_MODEL_52c78b54840e4637afe29babad849a10","IPY_MODEL_4a27dfc8e32341fa9232cd8eb9cb2aeb"],"layout":"IPY_MODEL_87f2fa2907814a3fb9e221189c8d5454"}},"92033821313240abb255bc1c2954089d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5c49c9353b34d0da0892750ff5cb2b7","placeholder":"​","style":"IPY_MODEL_bb39bae8d8284385967738679845f8c6","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"52c78b54840e4637afe29babad849a10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_527a67259bbb43cfbda2138280c7bc90","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6f13f652e1f4b79b7c17a0084b25ded","value":440473133}},"4a27dfc8e32341fa9232cd8eb9cb2aeb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc60f53ecb8649bba2523036e4d5a62b","placeholder":"​","style":"IPY_MODEL_3aea37edfe3b476b80766f6093159029","value":" 440M/440M [00:05&lt;00:00, 86.2MB/s]"}},"87f2fa2907814a3fb9e221189c8d5454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5c49c9353b34d0da0892750ff5cb2b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb39bae8d8284385967738679845f8c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"527a67259bbb43cfbda2138280c7bc90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f13f652e1f4b79b7c17a0084b25ded":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc60f53ecb8649bba2523036e4d5a62b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aea37edfe3b476b80766f6093159029":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uA44ZPF0eyPO","executionInfo":{"status":"ok","timestamp":1675449231915,"user_tz":-120,"elapsed":13014,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"bb827226-efb6-4483-e937-3aebb6c63d3d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"]}]},{"cell_type":"code","source":["!pip install wget"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nWNRTxgae71h","executionInfo":{"status":"ok","timestamp":1675449239071,"user_tz":-120,"elapsed":7166,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"bda8a7ba-5c55-46de-877f-de9aae4bec10"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=c8e7a9e47afbdf28bc948811b17b076754e4d246fd74ef6e48793284ca711d1f\n","  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"]}]},{"cell_type":"code","source":["!pip install colorama"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dqpp0uJOfDMr","executionInfo":{"status":"ok","timestamp":1675449245059,"user_tz":-120,"elapsed":5996,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"fa2b9d38-5e1b-4f74-9dbe-3022b5d88b32"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Installing collected packages: colorama\n","Successfully installed colorama-0.4.6\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"A9qmEbb-aa3K","executionInfo":{"status":"ok","timestamp":1675449259932,"user_tz":-120,"elapsed":14879,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"outputs":[],"source":["\n","import numpy as np \n","import random \n","import time\n","import torch \n","import os \n","import wget \n","import pandas as pd \n","import colorama\n","import tensorflow as tf \n","\n","from tensorflow import keras\n","from transformers import BertTokenizer \n","from colorama import Fore\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader , TensorDataset ,RandomSampler , SequentialSampler\n","from transformers import BertForSequenceClassification  , AdamW , BertConfig\n","import warnings \n","warnings.simplefilter(\"ignore\")\n","from transformers import get_linear_schedule_with_warmup\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["device ='cuda' if torch.cuda.is_available() else 'cpu' "],"metadata":{"id":"XOPQHjB5eubW","executionInfo":{"status":"ok","timestamp":1675449259935,"user_tz":-120,"elapsed":11,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n","\n","if not os.path.exists('./cola_public_1.1.zip'):\n","    wget.download(url ,'./cola_public_1.1.zip')"],"metadata":{"id":"5PskOHGafYlp","executionInfo":{"status":"ok","timestamp":1675449260444,"user_tz":-120,"elapsed":519,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists('./cola_public/'):\n","    !unzip cola_public_1.1.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ORlUdJeffcW","executionInfo":{"status":"ok","timestamp":1675449260445,"user_tz":-120,"elapsed":46,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"bc359010-a8a8-4c23-aadc-0cf1cff8b0dd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  cola_public_1.1.zip\n","   creating: cola_public/\n","  inflating: cola_public/README      \n","   creating: cola_public/tokenized/\n","  inflating: cola_public/tokenized/in_domain_dev.tsv  \n","  inflating: cola_public/tokenized/in_domain_train.tsv  \n","  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n","   creating: cola_public/raw/\n","  inflating: cola_public/raw/in_domain_dev.tsv  \n","  inflating: cola_public/raw/in_domain_train.tsv  \n","  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"]}]},{"cell_type":"code","source":["\n","train_data = pd.read_csv('./cola_public/raw/in_domain_train.tsv' , sep ='\\t' , header = None , \n","                        names = ['sentence_source' , 'label' , 'label_notes' ,'sentence'])"],"metadata":{"id":"8SUjApwkfhsy","executionInfo":{"status":"ok","timestamp":1675449260446,"user_tz":-120,"elapsed":42,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"vmtBji4xfuos","executionInfo":{"status":"ok","timestamp":1675449260447,"user_tz":-120,"elapsed":43,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"75a3d4e8-a3d0-480b-f1b9-b957c6c1dca9"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  sentence_source  label label_notes  \\\n","0            gj04      1         NaN   \n","1            gj04      1         NaN   \n","2            gj04      1         NaN   \n","3            gj04      1         NaN   \n","4            gj04      1         NaN   \n","\n","                                            sentence  \n","0  Our friends won't buy this analysis, let alone...  \n","1  One more pseudo generalization and I'm giving up.  \n","2   One more pseudo generalization or I'm giving up.  \n","3     The more we study verbs, the crazier they get.  \n","4          Day by day the facts are getting murkier.  "],"text/html":["\n","  <div id=\"df-352d4c5b-603a-421b-8aab-7a482c528e23\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_source</th>\n","      <th>label</th>\n","      <th>label_notes</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Our friends won't buy this analysis, let alone...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>One more pseudo generalization and I'm giving up.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>One more pseudo generalization or I'm giving up.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>The more we study verbs, the crazier they get.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Day by day the facts are getting murkier.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-352d4c5b-603a-421b-8aab-7a482c528e23')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-352d4c5b-603a-421b-8aab-7a482c528e23 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-352d4c5b-603a-421b-8aab-7a482c528e23');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["sentence = train_data['sentence'].values\n","label = train_data['label'].values"],"metadata":{"id":"UG9UpbEjfxDQ","executionInfo":{"status":"ok","timestamp":1675449260448,"user_tz":-120,"elapsed":41,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","print('Downloading model.....')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased' , do_lower_case =True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["bd73fe6608a6415fbc2dcd716170495c","c04ea682c6ba48089c45fb977e5b3dcd","9bec03f0183349d2a24c0fa5e41f9357","a4ead4777c2e42d9be36337aefa489b0","8b0e8399b1ac489b8a98652d53070c01","cb0f5a203bb841309da02c77d848aad5","8d3c6335f8f640e1aa23641a25dde411","6fafb479fa534712a7ea63b535f05076","a0f77f7a998b459ca982365083515a45","911b97cf15374092be785cb9e6666853","58780d38cf9a4dfbafcc7add93be7ccf","9550fb842c3449d397d573be736fae7f","fa30bf91827e4a849eddcbb737749861","e4f9724ab36344d293f6efb37a462f15","b603bbd46b2d4fe79169bda5533b4cf6","4f4908fc003c40ec92c0ceecd2e9b690","59c27d9003684277bbeeaf92bba37e59","57336f7802d941fab459d122d2671851","a0f756f2744f48c9a48601cfe6a16ef5","c9238bab39854b539ec93d7221b38fd0","59a64c983a144e499e27a2c467403143","49a562e48d044c1abe18f72e98f819d7","478134f5264040dc9b1a1590b823063c","efe7d778a22248b985d2c355b02e0d75","b992b46c5c4d44ac9768d0a3c3d9eb37","ab21bb95bde2449b8836d7ba04ee8c84","79cc888a6c3b4892b2418dce30782b11","91d8ab2a0a9c4ea9b9712cc1a93538f4","34cb562d7a764d49add996a7c6da46fa","05b334ad42cb446cb6e3baa5612a7184","5c48f982799342c1b2146476bd25548c","daed9f1a6d5a4e9c852060d010dd7374","d294bf386321402cbde519827887f67f"]},"id":"XzhFIzl_f1Wb","executionInfo":{"status":"ok","timestamp":1675449261290,"user_tz":-120,"elapsed":882,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"c521fd53-d5bf-4097-a8fa-d2ba335ddfc4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading model.....\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd73fe6608a6415fbc2dcd716170495c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9550fb842c3449d397d573be736fae7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"478134f5264040dc9b1a1590b823063c"}},"metadata":{}}]},{"cell_type":"code","source":["## testing our model \n","print(f'Original sentence:\\n {sentence[0]}\\n ')\n","print(f'sentence tokens :\\n {tokenizer.encode(sentence[0])}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sTycpdf9f7BB","executionInfo":{"status":"ok","timestamp":1675449261293,"user_tz":-120,"elapsed":13,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"5b2fd39c-271e-486d-e0f1-f501cb36f428"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Original sentence:\n"," Our friends won't buy this analysis, let alone the next one we propose.\n"," \n","sentence tokens :\n"," [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"]}]},{"cell_type":"code","source":["## we will do :\n","# 1. token sentence \n","# 2. add special tokens like -->[SEP , CLS]\n","# 3. turn it to ids \n","\n","get_ids = []\n","\n","for sent in sentence :\n","    tokens  = tokenizer.encode(sent  , add_special_tokens = True)\n","    get_ids.append(tokens)\n"],"metadata":{"id":"58TMHjm7f9_Z","executionInfo":{"status":"ok","timestamp":1675449265252,"user_tz":-120,"elapsed":3968,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["\n","print(f'Original sentence:--> {sentence[0]}')\n","print(Fore.GREEN +f'Sentence Tokens:----> {get_ids[0]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGr8TZnBgH9K","executionInfo":{"status":"ok","timestamp":1675449265253,"user_tz":-120,"elapsed":17,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"d91fff44-05a7-443f-94cd-257cbd08157a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Original sentence:--> Our friends won't buy this analysis, let alone the next one we propose.\n","\u001b[32mSentence Tokens:----> [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"]}]},{"cell_type":"code","source":["## here we will adding padding values \n","\n","print(Fore.LIGHTBLUE_EX+  f'Max Length of sentence {Fore.GREEN+str(max([len(sent) for sent in get_ids]))}\\n')  ### so we will use 64 as max of lenth to matched to processor \n","\n","\n","from keras.utils import pad_sequences\n","max_len = 64 \n","inputs_ids = pad_sequences(get_ids , maxlen =max_len , dtype = 'long', value = 0 ,\n","                           padding = 'post' , truncating='post')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKBl6eURgNPa","executionInfo":{"status":"ok","timestamp":1675449265254,"user_tz":-120,"elapsed":14,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"8f0f7ded-a889-44f6-d958-154b6c18e494"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[94mMax Length of sentence \u001b[32m47\n","\n"]}]},{"cell_type":"code","source":["for i in range(5):\n","    print(inputs_ids[i])\n","    print(f'it is lenght is :{len(inputs_ids[i])}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAVsqfyfgWpL","executionInfo":{"status":"ok","timestamp":1675449265254,"user_tz":-120,"elapsed":10,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"8bbcb865-5a3e-430e-b6b3-0fe7e20f04e6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[  101  2256  2814  2180  1005  1056  4965  2023  4106  1010  2292  2894\n","  1996  2279  2028  2057 16599  1012   102     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","it is lenght is :64\n","\n","[  101  2028  2062 18404  2236  3989  1998  1045  1005  1049  3228  2039\n","  1012   102     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","it is lenght is :64\n","\n","[  101  2028  2062 18404  2236  3989  2030  1045  1005  1049  3228  2039\n","  1012   102     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","it is lenght is :64\n","\n","[  101  1996  2062  2057  2817 16025  1010  1996 13675 16103  2121  2027\n","  2131  1012   102     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","it is lenght is :64\n","\n","[  101  2154  2011  2154  1996  8866  2024  2893 14163  8024  3771  1012\n","   102     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","it is lenght is :64\n","\n"]}]},{"cell_type":"markdown","source":["# Attention Mask"],"metadata":{"id":"oRfBvVKGhIF-"}},{"cell_type":"code","source":["# makes it explicit which tokens are actual words versus which are padding \n","## all values (0 or 1) so 0----> is padding values ,  1----> is real values\n","\n","attention_mask = []\n","\n","for ids in inputs_ids :\n","    mask = [int(tokens>0) for tokens in ids]\n","    attention_mask.append(mask)"],"metadata":{"id":"GZ1MCtRThEQV","executionInfo":{"status":"ok","timestamp":1675449265984,"user_tz":-120,"elapsed":738,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["## spliting data \n","\n","\n","X_train , X_val , y_train ,y_val = train_test_split(inputs_ids , label , test_size =0.1  \n","                                                    , random_state=2023)\n","train_mask , val_mask = train_test_split(attention_mask , test_size=0.1 , random_state=2023 )"],"metadata":{"id":"lMg2DTUAhRaB","executionInfo":{"status":"ok","timestamp":1675449265985,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# transform data into tensors"],"metadata":{"id":"ksKbIt3Dhoaq"}},{"cell_type":"code","source":["#preparation data for torch :\n","train_input = torch.tensor(X_train) \n","val_input = torch.tensor(X_val)\n","train_label = torch.tensor(y_train)\n","val_label = torch.tensor(y_val)\n","\n","tr_mask = torch.tensor(train_mask)\n","vl_mask = torch.tensor(val_mask)\n"],"metadata":{"id":"akMMUqwZhchu","executionInfo":{"status":"ok","timestamp":1675449266601,"user_tz":-120,"elapsed":620,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","\n","train_data = TensorDataset(train_input , tr_mask ,train_label)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data , sampler=train_sampler , batch_size=batch_size)\n","\n","\n","\n","validation_data = TensorDataset(val_input ,vl_mask ,val_label)\n","validation_sampler = RandomSampler(validation_data)\n","val_dataloader = DataLoader(validation_data ,sampler =validation_sampler ,batch_size=batch_size)"],"metadata":{"id":"0bUhkfTphkY7","executionInfo":{"status":"ok","timestamp":1675449266602,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["\n","# Calling model from Hugging Face \n","model  = BertForSequenceClassification.from_pretrained('bert-base-uncased' , num_labels =2 ,\n","                                                   output_attentions=False , \n","                                                   output_hidden_states = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["960fc6bfacac4457b4b7214506807f84","92033821313240abb255bc1c2954089d","52c78b54840e4637afe29babad849a10","4a27dfc8e32341fa9232cd8eb9cb2aeb","87f2fa2907814a3fb9e221189c8d5454","f5c49c9353b34d0da0892750ff5cb2b7","bb39bae8d8284385967738679845f8c6","527a67259bbb43cfbda2138280c7bc90","f6f13f652e1f4b79b7c17a0084b25ded","fc60f53ecb8649bba2523036e4d5a62b","3aea37edfe3b476b80766f6093159029"]},"id":"LW8V7TvZhuLL","executionInfo":{"status":"ok","timestamp":1675449275238,"user_tz":-120,"elapsed":8643,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"4dda380c-3141-4e5d-83fd-d9604bb5e583"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"960fc6bfacac4457b4b7214506807f84"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9lC0-kbh0Ha","executionInfo":{"status":"ok","timestamp":1675449275239,"user_tz":-120,"elapsed":44,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}},"outputId":"42543205-2bef-4856-ec6b-d6fa8b952f93"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters() ,lr=2e-5 , eps =1e-8)\n","epochs = 4\n","all_steps  = len(train_dataloader) * epochs\n","\n","\n","schedual = get_linear_schedule_with_warmup(optimizer , num_warmup_steps =0 ,\n","                                     num_training_steps = all_steps)\n","\n"],"metadata":{"id":"T7Q0PQITh6_u","executionInfo":{"status":"ok","timestamp":1675449275240,"user_tz":-120,"elapsed":40,"user":{"displayName":"Ahmed Toba","userId":"04457414598699327477"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n","seed_value = 42 \n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","torch.manual_seed(seed_value)\n","torch.cuda.manual_seed_all(seed_value)\n","\n","\n","\n","total_loss =[]\n","for i in range(epochs):\n","    print(f'===== spochs {i+1}=====')\n","    tic = time.time()\n","    loss_val = 0\n","    \n","            #######################\n","            #### train model ######\n","            #######################\n","    model.train()\n","    \n","    for step , batch in enumerate(train_dataloader):\n","        inp_ids = batch[0].to(device)\n","        inp_mask = batch[1].to(device)\n","        inp_labels = batch[2].to(device)\n","        \n","        model.zero_grad()\n","        outputs = model(inp_ids ,token_type_ids = None ,  \n","                        attention_mask = inp_mask , labels = inp_labels)\n","        loss = outputs[0]\n","        loss_val+=loss \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        schedual.step()\n","    toc = time.time()    \n","    av_loss = loss_val / len(train_dataloader)\n","    total_loss.append(av_loss)\n","    \n","    \n","    print(f'average of loss : {av_loss} time is ----> {tic-toc}')\n","    \n","    \n","            ###########################\n","            ###### validation #########\n","            ###########################\n","    \n","    print('Running Validation......')\n","    num_steps =0\n","    tic_2 = time.time()\n","    model.eval()\n","    accuracy = 0 \n","    \n","    for batch in (val_dataloader) :\n","        inp_ids = batch[0].to(device)\n","        inp_mask = batch[1].to(device)\n","        inp_labels = batch[2].to(device)\n","        \n","        with torch.no_grad():\n","            outputs = model(inp_ids , attention_mask=inp_mask , token_type_ids =None)\n","\n","            prediction = outputs[0]\n","\n","            out_1 = np.argmax(prediction , axis=1).flatten()\n","            out_2 = inp_labels.flatten()\n","            acc = np.sum(out_1==out_2) / len(inp_labels)\n","            accuracy+=acc\n","            num_steps+=1\n","\n","    toc_2 = time.time()\n","    print(f'accurcy is {accuracy / num_steps} time is ---->{tic_2 -toc_2} ')\n","    \n","print('Completed .')\n"," "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zxBSZhph-kc","outputId":"d4fbd9e5-8108-41f6-b19b-9f8de76de949"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["===== spochs 1=====\n"]}]}]}